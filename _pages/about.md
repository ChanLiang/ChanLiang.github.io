---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---



Liang Chen is a third-year Ph.D. student in the Department of Systems Engineering and Engineering Management at The Chinese University of Hong Kong (CUHK), advised by [Prof. Kam-Fai Wong](https://www1.se.cuhk.edu.hk/~kfwong/). He received his master and bachelor degrees from Peking University and Northwestern Polytechnical University, respectively. Currently, he is a visiting researcher at LMU Munich, working with [Prof. Hinrich Schütze](https://cisnlp.github.io/about/).


His research interests lie in natural language processing and machine learning, with a focus on trustworthy large language models (LLMs). To this end, he develops novel methods to promote the reliability of LLMs across training ([ICML 2025](https://arxiv.org/abs/2506.03850), [ICLR 2025](https://openreview.net/pdf?id=txoJvjfI9w)), inference ([ACL 2024](https://aclanthology.org/2024.acl-long.496.pdf)), and evaluation ([EMNLP 2023](https://aclanthology.org/2023.emnlp-main.390)). Recently, he has been working on reinforcement learning (RL) and large reasoning models. 
<!-- Further details can be found in the [research portfolio](https://chanliang.github.io/portfolio/portfolio-1/). -->

## Research Portfolio

<!-- <img src="/images/trust-llm.png" alt="LLM Trustworthiness" style="width: 65%; display: block; margin: auto;" /> -->
<!-- <img src="/images/trustllm2.png" alt="LLM Trustworthiness" style="width: 65%; display: block; margin: auto;" /> -->
<img src="/images/TrustLLM.png" alt="LLM Trustworthiness" style="width: 65%; display: block; margin: auto;" />

He is dedicated to enhancing the reliability of LLMs across four dimensions:
- **Robustness to Input**: Ensuring LLMs can handle adversarial attacks and distribution shifts ([ICLR 2025](https://openreview.net/pdf?id=txoJvjfI9w)).
- **Transparency of Decision**: Improving interpretability techniques and reasoning models ([BRIDGE](/talks/bridge.pdf)).
- **Validity of Output**: Addressing hallucinations ([EMNLP 2023](https://aclanthology.org/2023.emnlp-main.390)) and inconsistencies in model outputs ([ACL 2023 findings](https://aclanthology.org/2023.findings-acl.462)).
- **Resistance to Misuse**: Preventing the use of AI for cheating, plagiarism ([ACL 2024](https://aclanthology.org/2024.acl-long.496.pdf)), and unsafe fine-tuning ([ICML 2025](https://openreview.net/pdf?id=EMHED4WTHT)).

## News

- [09/2025] [New preprint](/talks/bridge.pdf): Cooperative SFT–RL training for advanced reasoning.  
  We enable RL to meta-learn from SFT signals, selectively incorporating beneficial knowledge to achieve superior reasoning performance.

<!-- - [05/2025] **Gave a talk at LMU Munich on post-training optimization for trustworthy LLMs.** -->
<!-- - [05/2025] **Gave a talk at LMU Munich on robust LLMs.** -->
- [05/2025] Gave a talk at LMU Munich on robust LLMs.

<!-- - [05/2025] Our paper on Vulnerability-Aware Alignment (VAA) is accepted at ICML 2025.   -->
<!-- - [05/2025] **Our paper on safety alignment is accepted at ICML 2025.**   -->
<!-- - [05/2025] Our paper on [safety alignment](https://icml.cc/virtual/2025/poster/45951) is accepted at ICML 2025.   -->
- [05/2025] Our paper on [safety alignment](https://arxiv.org/abs/2506.03850) is accepted at ICML 2025.  
  <!-- We reveal that some alignment examples are more prone to forgetting, and propose to upweight and reinforce them to improve safety retention. -->
  <!-- We reveal that some alignment examples are more prone to forgetting, and propose a vulnerability-aware alignment method to upweight and reinforce them to improve safety retention. -->
  <!-- We reveal that some alignment examples are more prone to forgetting, and propose to upweight and reinforce them to improve safety retention. -->
  We reveal that some alignment examples are more prone to forgetting, and propose to upweight them to improve safety retention.
  <!-- We reveal that some alignment examples are more prone to forgetting during finetuning, and propose prioritizing them to improve long-term safety. -->
  

<!-- - [02/2025] Our paper on Permutation-Resilient Learning (PEARL) is accepted at ICLR 2025.   -->
<!-- - [02/2025] **Our paper on [robust finetuning](https://openreview.net/pdf?id=txoJvjfI9w) is accepted at ICLR 2025.**   -->
<!-- - [02/2025] Our paper on [robust instruction tuning](https://openreview.net/pdf?id=txoJvjfI9w) is accepted at ICLR 2025.   -->
- [02/2025] Our paper on [robust finetuning](https://openreview.net/pdf?id=txoJvjfI9w) is accepted at ICLR 2025.  
  <!-- PEARL helps LLMs understand unordered inputs — making them more robust in tasks like ICL and RAG. -->
  <!-- We propose a permutation-resilient finetuning method that helps LLMs understand unordered inputs — making them more robust in tasks like ICL and RAG. -->
  <!-- We propose a permutation-resilient finetuning method that helps LLMs better handle unordered inputs — making them more robust in tasks like ICL and RAG. -->
  We propose an instruction finetuning method that helps LLMs better handle unordered inputs — making them more robust in tasks like ICL and RAG.
  <!-- We propose an instruction tuning method that helps LLMs better handle unordered inputs, improving robustness in tasks like ICL and RAG. -->


<!-- - [08/2024] **One collaborative paper on [consecutive model editing](https://aclanthology.org/2024.emnlp-main.765) is accepted at EMNLP 2024.**   -->
- [08/2024] One collaborative paper on [model editing](https://aclanthology.org/2024.emnlp-main.765) is accepted at EMNLP 2024.  
  
<!-- - [05/2024] Our paper on Lossless text watermarking (WatME) is accepted at ACL 2024. -->
<!-- - [05/2024] **Our paper on [lossless text watermarking](https://aclanthology.org/2024.acl-long.496.pdf) is accepted at ACL 2024.**   -->
- [05/2024] Our paper on [text watermarking](https://aclanthology.org/2024.acl-long.496.pdf) is accepted at ACL 2024.   
  <!-- We improve decoding algorithms by leveraging lexical redundancy to achieve lossless watermarking in text, mirroring the success of image watermarking. -->
  <!-- We improve decoding algorithms by leveraging lexical redundancy to mirror the success of image watermarking. -->
  <!-- We improve decoding algorithms by leveraging lexical redundancy to achieve lossless text watermarking, mirroring the success of image watermarking. -->
  <!-- We improve decoding algorithms by leveraging lexical redundancy to embed watermarks in text losslessly, mirroring the success of image watermarking. -->
  <!-- We propose a novel LM decoding method that embeds watermarks by exploiting lexical redundancy, minimizing impact on text quality. -->
  We introduce a decoding method that embeds watermarks via lexical redundancy, preserving text quality with minimal tradeoff.

<!-- - [01/2024] One collaborative paper on [jailbreak attack](https://aclanthology.org/2024.naacl-long.92) is accepted at NAACL 2024.   -->

<!-- - [10/2023] Our paper on [automatic evaluation](https://aclanthology.org/2023.emnlp-main.390) is accepted at EMNLP 2023.   -->
  <!-- We propose a comprehensively framework to assess LLM-generated knowledge and explore the impact of generative search engineering over traditional IR. -->
  <!-- We propose a comprehensive framework to assess LLM-generated knowledge and discuss the potential of generative search engineering as a superior alternative to traditional IR. -->
  <!-- We propose a comprehensive framework to assess LLM-generated knowledge and discuss the possibility of generative search engineering as an alternative to traditional IR. -->
  <!-- We propose a framework to automatically assess LLM-generated knowledge and explore the impact of replacing traditional IR with generative search engineering. -->
  <!-- We introduce a framework to systematically evaluate LLM-generated knowledge and highlight the impact of replacing traditional IR with generative search engineering. -->

<!-- - [05/2023] Our paper on [robust dialogue](https://aclanthology.org/2023.findings-acl.462/) is accepted at ACL 2023 findings.  
  We propose a simple regularizer to help conversational AI learn robust representations, improving the consistency of model responses. -->


## Publications ([Full List](https://scholar.google.com/citations?hl=en&user=0iatxnIAAAAJ&view_op=list_works&sortby=pubdate))

- **Liang Chen**, Xueting Han, Li Shen, Jing Bai, Kam-Fai Wong.  
  [Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning](/talks/bridge.pdf)  
  **Preprint**

- **Liang Chen**, Xueting Han, Li Shen, Jing Bai, Kam-Fai Wong.  
  [Vulnerability-Aware Alignment: Mitigating Uneven Forgetting in Harmful Fine-Tuning](https://openreview.net/pdf?id=EMHED4WTHT)  
  **ICML 2025**

- **Liang Chen**, Li Shen, Yang Deng, Xiaoyan Zhao, Bin Liang, Kam-Fai Wong.  
  [PEARL: Towards Permutation-Resilient LLMs](https://openreview.net/pdf?id=txoJvjfI9w)  
  **ICLR 2025**

- **Liang Chen**, Yatao Bian, Yang Deng, Deng Cai, Shuaiyi Li, Peilin Zhao, Kam-Fai Wong.  
  [WatME: Towards Lossless Watermarking Through Lexical Redundancy](https://aclanthology.org/2024.acl-long.496.pdf)  
  **ACL 2024**

- **Liang Chen**, Yang Deng, Yatao Bian, Zeyu Qin, Bingzhe Wu, Tat-Seng Chua, Kam-Fai Wong.  
  [Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators](https://aclanthology.org/2023.emnlp-main.390)  
  **EMNLP 2023**

- **Liang Chen**, Hongru Wang, Yang Deng, Wai Chung Kwan, Zezhong Wang, Kam-Fai Wong.    
  [Towards Robust Personalized Dialogue Generation via Representation Regularization](https://aclanthology.org/2023.findings-acl.462/) 
  **Findings of ACL 2023**

- Shuaiyi Li, Yang Deng, Deng Cai, Hongyuan Lu, **Liang Chen**, Wai Lam.  
  [Consecutive Model Editing with Batch alongside HooK Layers](https://aclanthology.org/2024.emnlp-main.765)  
  **EMNLP 2024**

- Zezhong Wang, Fangkai Yang, Lu Wang, Pu Zhao, Hongru Wang, **Liang Chen**, Qingwei Lin, Kam-Fai Wong.  
  [SELF-GUARD: Empower the LLM to Safeguard Itself](https://aclanthology.org/2024.naacl-long.92)  
  **NAACL 2024**

<!-- - Yang Deng, Lizi Liao, **Liang Chen**, Hongru Wang, Wenqiang Lei, Tat-Seng Chua.  
  [Proactive Dialogue Systems in the Era of Large Language Models: Evaluating from a Prompting Perspective](https://openreview.net/forum?id=LPtO1evrGa)  
  **Findings of EMNLP 2023** -->

---

## Talks

<!-- - **Towards Trustworthy LLMs: Improving Robustness via Post-Training Optimization**  
  PhD Seminar, LMU Munich  
  May 2025   -->
  <!-- [[Slides]](/talks/pearl.pdf) -->

- **Beyond Two-Stage Training: Cooperative SFT and RL for Improved LLM Reasoning**
  *PhD Seminar*, LMU Munich – August 2025  
  Host: Prof. Hinrich Schütze

- **Vulnerability-Aware Alignment: Protect Open-Source LLMs against Unsafe Fine-tuning**
  *AI Time*, Online Live – June 2025  

- **Towards Trustworthy LLMs: Improving Robustness via Post-Training Optimization**  
  *PhD Seminar*, LMU Munich – May 2025  
  Host: Prof. Hinrich Schütze

---

## Teaching

I have served as a teaching assistant for the following courses:

- **Operations Research II (SEEM3440)** – Covers advanced optimization techniques, including non-linear, integer, and dynamic programming.  
- **Engineering Innovation and Entrepreneurship (SEEM3450)** – A hands-on course focused on identifying engineering opportunities and developing business plans.

---

## Internships

- Microsoft Research Asia, Systems Research Group
- Tencent AI Lab, Machine Learning Center

---

## Community Service

<!-- - Reviewer for: ICML 2024, ICLR 2025, NeurIPS 2024-2025, AISTATS 2025, ACL 2024-2025, EMNLP 2023–2024 -->

- Reviewer for ICML, ICLR, NeurIPS, AISTATS, ACL, EMNLP, and NAACL.

---

<!-- ## Skills

- **Programming Languages**: Python, Shell, Java  
- **Frameworks**: PyTorch, PaddlePaddle, TensorFlow, Huggingface Transformers, Fairseq  
- **Operating Systems**: Linux -->

<!-- --- -->

## Honors & Scholarships

- Postgraduate Studentship, CUHK  
- School Scholarship, PKU
- First-Class Scholarship, NWPU

---

## Miscellaneous

Outside of research, I enjoy walking in the park, as well as sports like swimming, hiking, and table tennis.
  
During my time at NWPU, I was the runner-up in the Freshmen Cup table tennis singles match and won the team championship three times.

---


<!-- <p style="text-align: center; font-style: italic; color: gray; margin-top: 3rem;">
  <span style="white-space: nowrap;">
    “I don't want to achieve immortality through my work; I want to achieve immortality through not dying.”
  </span><br>
  — Woody Allen
</p> -->

<p style="text-align: center; font-style: italic; color: gray; margin-top: 3rem; font-size: 0.85rem;">
  <span style="white-space: normal;">
    “I don't want to achieve immortality through my work; I want to achieve immortality through not dying.”
  </span><br>
  — Woody Allen
</p>