---
title: "Research"
layout: single
permalink: /research/
redirect_from: 
  - /research/
  - /research.html
---

## Research Focus

![LLM Trustworthiness](/images/llm-trustworthiness.png)

The diagram illustrates the four key aspects of LLM trustworthiness:
- **Robustness to Input**: Ensuring LLMs can handle adversarial attacks and distribution shifts ([ICLR 2025](https://openreview.net/pdf?id=txoJvjfI9w)).
- **Transparency of Decision**: Improving reasoning models and long-chain-of-thought ([Coming Soon](#)).
- **Validity of Output**: Addressing factual errors ([EMNLP 2023](https://aclanthology.org/2023.emnlp-main.390)) and inconsistencies in outputs ([ACL 2023 findings](https://aclanthology.org/2023.findings-acl.462)).
- **Resistance to Misuse**: Preventing cheating, plagiarism ([ACL 2024](https://aclanthology.org/2024.acl-long.496.pdf)), and unsafe fine-tuning ([ICML 2025](https://icml.cc/virtual/2025/poster/45951)).

From a systems perspective, the first three aspects correspond to the input, hidden states, and output of the system. The final aspect represents the relationship between the system and its users.

_Last updated: June 2025_